{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch_snippets import stems, read\n",
    "from enel645_group5_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device being used is: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(\"The device being used is:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet().to(device)\n",
    "\n",
    "PATH = './best_model.pth' # Path to save the best model\n",
    "net.load_state_dict(torch.load(PATH, map_location=torch.device(device)))\n",
    "\n",
    "test_ds = SegmentationDataset('test')\n",
    "\n",
    "test_dl = DataLoader(test_ds, batch_size=8, collate_fn=test_ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #1. RUNNING IoU: 0.8787014484405518\n",
      "Batch #2. RUNNING IoU: 0.8510059714317322\n",
      "Batch #3. RUNNING IoU: 0.8343911170959473\n",
      "Batch #4. RUNNING IoU: 0.8190805912017822\n",
      "Batch #5. RUNNING IoU: 0.815911591053009\n",
      "Batch #6. RUNNING IoU: 0.8244231343269348\n",
      "Batch #7. RUNNING IoU: 0.8189253211021423\n",
      "Batch #8. RUNNING IoU: 0.8144890069961548\n",
      "Batch #9. RUNNING IoU: 0.8137295842170715\n",
      "Batch #10. RUNNING IoU: 0.8117858171463013\n",
      "Batch #11. RUNNING IoU: 0.8026285171508789\n",
      "Batch #12. RUNNING IoU: 0.8021677136421204\n",
      "Batch #13. RUNNING IoU: 0.798139214515686\n",
      "Batch #14. RUNNING IoU: 0.8005191683769226\n",
      "Batch #15. RUNNING IoU: 0.8017549514770508\n",
      "Batch #16. RUNNING IoU: 0.8017579317092896\n",
      "Batch #17. RUNNING IoU: 0.8045522570610046\n",
      "Batch #18. RUNNING IoU: 0.8025670647621155\n",
      "Batch #19. RUNNING IoU: 0.8026304244995117\n",
      "Batch #20. RUNNING IoU: 0.8039429783821106\n",
      "Batch #21. RUNNING IoU: 0.805064857006073\n",
      "Batch #22. RUNNING IoU: 0.8062458038330078\n",
      "Batch #23. RUNNING IoU: 0.8068971037864685\n",
      "Batch #24. RUNNING IoU: 0.8075928688049316\n",
      "Batch #25. RUNNING IoU: 0.806368350982666\n",
      "Batch #26. RUNNING IoU: 0.8076447248458862\n",
      "Batch #27. RUNNING IoU: 0.8091763854026794\n",
      "Batch #28. RUNNING IoU: 0.8110895156860352\n",
      "Batch #29. RUNNING IoU: 0.8092023134231567\n",
      "Batch #30. RUNNING IoU: 0.8092452883720398\n",
      "Batch #31. RUNNING IoU: 0.8085022568702698\n",
      "Batch #32. RUNNING IoU: 0.8098363876342773\n",
      "Batch #33. RUNNING IoU: 0.8095186352729797\n",
      "Batch #34. RUNNING IoU: 0.8098419904708862\n",
      "Batch #35. RUNNING IoU: 0.8103468418121338\n",
      "Batch #36. RUNNING IoU: 0.8047059178352356\n",
      "Batch #37. RUNNING IoU: 0.8032603859901428\n",
      "Batch #38. RUNNING IoU: 0.7985610365867615\n",
      "Batch #39. RUNNING IoU: 0.7964804768562317\n",
      "Batch #40. RUNNING IoU: 0.7876601219177246\n",
      "Batch #41. RUNNING IoU: 0.7869478464126587\n",
      "Batch #42. RUNNING IoU: 0.7887980937957764\n",
      "Batch #43. RUNNING IoU: 0.7907910943031311\n",
      "Batch #44. RUNNING IoU: 0.7928731441497803\n",
      "Batch #45. RUNNING IoU: 0.7946532368659973\n",
      "Batch #46. RUNNING IoU: 0.7960001230239868\n",
      "Batch #47. RUNNING IoU: 0.7974296808242798\n",
      "Batch #48. RUNNING IoU: 0.7988254427909851\n",
      "Batch #49. RUNNING IoU: 0.7999264597892761\n",
      "Batch #50. RUNNING IoU: 0.8015902638435364\n",
      "Batch #51. RUNNING IoU: 0.8034970164299011\n",
      "Batch #52. RUNNING IoU: 0.8049455881118774\n",
      "Batch #53. RUNNING IoU: 0.806128978729248\n",
      "Batch #54. RUNNING IoU: 0.8077808618545532\n",
      "Batch #55. RUNNING IoU: 0.8093575835227966\n",
      "Batch #56. RUNNING IoU: 0.8106852769851685\n",
      "Batch #57. RUNNING IoU: 0.8116472363471985\n",
      "Batch #58. RUNNING IoU: 0.8113212585449219\n",
      "Batch #59. RUNNING IoU: 0.8105171918869019\n",
      "Batch #60. RUNNING IoU: 0.8103669285774231\n",
      "Batch #61. RUNNING IoU: 0.8112752437591553\n",
      "Batch #62. RUNNING IoU: 0.8122344613075256\n",
      "Batch #63. RUNNING IoU: 0.8128395080566406\n",
      "IoU of the network on the test images: 81.28395080566406 %\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import JaccardIndex\n",
    "jaccard = JaccardIndex(task=\"multiclass\", num_classes=34, average = \"weighted\")\n",
    "runningIoU = 0\n",
    "total_batches = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dl):\n",
    "        images, ground_truth_masks = data\n",
    "        _masks = net(images)\n",
    "        IoU = jaccard(_masks, ground_truth_masks)\n",
    "        runningIoU = runningIoU + IoU\n",
    "        total_batches = i + 1\n",
    "        print(f\"Batch #{total_batches}. RUNNING IoU: {runningIoU / total_batches}\")\n",
    "\n",
    "print(f'IoU of the network on the test images: {runningIoU / total_batches *100} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensf-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
